# UPSNet: A Unified Panoptic Segmentation Network

* https://arxiv.org/abs/1901.03784
* 초안 19.01 / CVPR 2019
* Uber ATG 등 (Yuwen Xiong, Renjie Liao, Hengshuang Zhao, Rui Hu, Min Bai, Ersin Yumer, Raquel Urtasun)



## Abstract & 5. Conclusion

* panoptic segmentation
  * ※ 2018년 1월 첫 발표되었던 Facebook의 ["Panoptic Segmentation" 논문](https://arxiv.org/abs/1801.00868)에서 제안된 Task
  * ![image-20220217113309750](https://user-images.githubusercontent.com/38153357/154633504-50f16f46-5ee0-4c9e-976d-9feb0c131897.png)
  * panoptic segmentation = semantic segmentation + instance segmentation

* Unified Panoptic Segmentation Network (UPSNet)은 하나의 backbone과 두 개의 경량화된 head로 semantic / instance segmentation을 동시에 수행
  * 1) deformable convolution based semantic segmentation head
  * 2) Mask R-CNN style instance segmentation head
* parameter가 없는 panoptic head
  * 두 head의 logit을 평가(leverage)
  * 학습되지 않은 class에 대해서도 예측이 가능한 flexibility 보유
* SoTA performance + fast inference speed
  * Cityscapes, COCO 데이터셋 및 자체 데이터셋으로 평가



## 1. Introduction

* 컴퓨터 비젼 분야에서의 발전 (선행연구)
  * ex/ Pyramid Scene Parsing Network (2017), FCN (2015) : **Semantic Segmentation**
    * 비슷한 패턴 혹은 재질을 가지는 무정형의 이미지 영역을 구분
  * ex/ Mask R-CNN (2017), Faster R-CNN (2015) : **Instance Segmentation**
    * countable object들의 구분
  * 두 task 모두 pixel level의 scene을 이해하는 것에 초점이 맞추어져 있음
  * 하지만 두 task에 대한 이분법적 접근으로 인해 두 task를 별도로 해결하기 위한 모델이 상이하게 발전해왔으며 서로 다른 구조를 갖게 됨
  * shared model 또는 representation으로 접근하면 큰 이점을 얻을 수 있음
* panoptic segmentation
  * 이전에도 image parsing, scene parsing, holistic scene understanding이라는 이름으로 동일 문제에 대한 연구가 진행 됨
  * panoptic segmentation에서 countable object는 "thing"으로, 무정형의 uncountable 지역은 "stuff"로 불림
    * 어떤 pixel이 "stuff"에 속하면 "stuff" class 중 하나로 분류하고, "thing"에 속하면 어떤 instance에 속하는지 결정하도록 학습
  * 기존에는 panoptic segmentation을 해결하기 위해 두개 별도 branch를 사용하는 모델을 이용
    → UPSNet의 경우에는 하나의 representation을 도출하는 하나의 backbone을 사용 + 두개의 head로 semantic / instance segmentation 동시 해결 + 최종 panoptic head
    * feature pyramid net (FPN)에서 multi-scale information을 도출
    * deformable convolution head를 통해 semantic segmentation
    * Mask R-CNN style head를 통해 instance segmentation (mask segmenation과 bounding box, 관련 class를 도출)
    * 최종 panoptic head는 semantic logit과 instance logit을 합치고, 추가로 unknown class 관련 logit을 새 채널로 추가하여 semantic / instance segmentation 간 충돌(conflict)를 줄이고 성능 증진



## 2. Related Work

### Semantic Segmentation

* 초창기 베이지안 기반 방법론으로 global context의 중요성을 보여줌(?)
* multi-scale feature aggregation : Pyramid Scene Parsing Network (2017), FCN (2015) 등
* end-to-end structured prediction : Conditional Random Field(CRF) 관련 모델들 등
* dilated convolution : 파라미터 수를 고정한 채 더 넓은 receptive field를 갖도록 하는 기법
  * ![dconv](https://cdn-images-1.medium.com/max/1200/1*SVkgHoFoiMZkjy54zM_SUw.gif)
  * PSPNet 등이 이 기법을 사용
* instance에 대해 boundary 정보를 제공하지 않음

### Instance Segmentation

* Region based R-CNN을 시작으로, segment proposal을 기반으로 하는 여러 모델 등장
* mask proposal과 Fully Convolutional Network의 융합 연구인 Mask R-CNN의 등장
* bounding box를 도출해냄
  * 이에 적합하지 않는 하늘, 도로 등을 무시하는 경향이 있음

### Panoptic Segmentation

- 이전 연구들과는 달리 UPSNet에서는 하나의 backbone으로부터 representation을 얻어서 semantic / instance segmentation에 모두 활용



## 3. Unified Panoptic Segmentation Network

* panoptic segmentation

  * "stuff" : instance boundary가 불분명한 무정형 영역 (ex/ street, sky)
  * "thing" : instance label들 (ex/ pedestrian, bicycle)

### 3.1 UPSNet Architecture

* ![image-20220217134946305](https://user-images.githubusercontent.com/38153357/154633596-6a235e15-7785-4ebf-ac71-428719509286.png)
  * 하나의 backbone + multiple head + single panoptic head

- feature pyramid network (FPN) backbone
  - ResNet을 이용하여 다양한 scale의 feature map을 모두 사용하는 구조
  - ![image-20220217142909239](https://user-images.githubusercontent.com/38153357/154633900-9ad59ce1-f183-4d51-a658-cce73d7be73c.png)
  - 입력층에 가까운 높은 해상도의 저수준 feature map들과 출력층에 가까운 낮은 해상도의 고수준 feature map들을 모두 사용하여 예측을 수행하는 방식
  - FPN 각 계층의 feature들은 **Region Proposal Network(RPN)**과, **Semantic** / **Instance Segmentation Head**의 입력으로 사용됨 (※ [코드](https://github.com/uber-research/UPSNet/blob/master/upsnet/models/resnet_upsnet.py) 참조)
    - Region Proposal Network는 Semantic / Instance Segmentation Head에 필요한 **Region of Interest(RoI)**를 계산하여 제공 (label이 제공되는 training 단계에서만 필요? ※ [코드](https://github.com/uber-research/UPSNet/blob/master/upsnet/models/resnet_upsnet.py) 참조)
- Instance Segmentation Head
  - Mask R-CNN의 구조
  - ![image-20220217140358034](https://user-images.githubusercontent.com/38153357/154633962-88ae0497-31d1-4095-822d-2d830229eaec.png)
  - 위의 classification branch는 **class label**과 **bbox offset**을 예측
  - 아래의 mask branch는 각각의 Region of Interest(RoI)에 대하여 class별로 **binary mask**를 출력
  - instance head를 통해서 "thing" class를 잘 설명할 수 있는 instance-aware representation을 만드는 것이 목표
- Semantic Segmentation Head
  - ![image-20220217135315986](https://user-images.githubusercontent.com/38153357/154634022-31c12b17-7491-4602-9ec7-8ee912d0d983.png)
  - 4개 계층의 feature를 사용하며, 각 feature map들은 **deformable convolution** (변형 가능한 합성곱)을 통해 같은 scale로 맞춰지고 합쳐짐
  - ![image-20220217145420839](https://user-images.githubusercontent.com/38153357/154634062-8ed37360-820a-41aa-99ab-5ba6ddc69682.png)
  - 각 계층의 feature map들에는 독립적으로 deformable convolution이 수행됨
  - 이후 upsampling을 통해 scale이 맞춰지고 concat됨
  - 1x1 conv + sofmax를 적용하여 semantic class를 예측할 수 있도록 함
  - semantic head에서 보행자 등의 foreground object를 강조하기 위해 **RoI loss**를 사용 - semantic segmentation 성능에 악영향을 끼치지 않은 채 panoptic segmentation의 성능을 증가
- Panoptic Head
  - ![image-20220217135359801](https://user-images.githubusercontent.com/38153357/154634096-39d8f412-d368-43f8-8bfa-b825169d1d8b.png)
  - Semantic Segmentation Head로부터 N_stuff개 채널의 데이터와, Instance Segmentation Head로부터 N_thing개 채널의 데이터를 얻음
  - instance의 개수는 training 단계에선 ground truth(사진의 실제 instance 개수)에 의존, inference 단계에선 **mask pruning**에 의존
  - (N_stuff + N_thing) x H x W 사이즈의 logit tensor Z를 만든 다음에 각 픽셀마다 클래스와 인스턴스 ID를 결정하는 것이 목적
  - 최종 1 + N_thing + N_stuff개 채널의 output 행렬이 만들어지며, channel-wise softmax를 적용. 각 픽셀의 클래스를 결정 (ex/ N_stuff개 원소 중 하나가 최대일 경우 "stuff"에 속하게 됨)
- Panoptic Quality (PQ) 지표
  - ![image-20220217154406575](https://user-images.githubusercontent.com/38153357/154634130-ee57abc0-ab2e-4e9e-8e48-10e59be55240.png)
  - Semantic Quality(SQ)와 Recognition Quality(RQ)를 합침
  - FP, FN이 늘어나면 PQ는 줄어들음
    - false positive : object를 잘못 예측 (ex/ dog를 person으로 예측)
    - false negative : object를 예측하지 못함 (ex/ 사람이 있는 영역에 사람을 발견하지 못함)
  - Interaction over Union (IoU)
    - ![image-20220218141848804](https://user-images.githubusercontent.com/38153357/154634182-569ed581-93ec-461c-b7f1-b3b5a4f2f938.png)
- Unknown Prediction
  - 추가적으로 하나의 채널을 더 부여하여, 모르는 항목에 대해서 오분류를 하지 않고 unknown class로 예측 하도록 유도
  - unknown class 분류 시, 클래스를 잘못 분류한 것으로 평가되지 않음 (ignored, set to void)
  - unknown prediction을 사용하지 않을때의 오분류 : FP와 FN이 둘다 1씩 오르는 구조
  - unknown prediction을 사용했을 때의 오분류 : FN만 1 오르고 FP는 그대로인 구조 → 평가 지표에 도움
  - generation of ground truth for unknown class : 30%의 ground truth mask를 unknown으로 설정

### 3.2 Implementation Details

- Region Proposal Network (RPN) (※ [코드](https://github.com/uber-research/UPSNet/blob/master/upsnet/models/resnet_upsnet.py#L52) 참조)
  - Semantic / Instance Segmentation Head에 집중해서 봐야할 영역을 제공
- Batch Normalization
  - do not fine-tune batch normalization for simplicity (batch normalization에 필요한 파라미터 고정)
  - 향후 실험에서 batch normalization 또한 fine-tune하면 성능이 오를 것으로 기대
- 8 losses in total (training)
  - RPN (weight 1.0)
    - box classification
    - box regression
  - semantic segmentation head (weight 0.2)
    - whole image based pixel-wise classification loss
    - RoI based pixel-wise classification loss
  - instance segmentation head (weight 1.0)
    - box classification
    - box regression
    - mask segmentation
  - panoptic segmentation head (weight 0.1)
    - whole image based pixel-wise classification loss
  - ※ loss balance strategy : assuring the scales of all losses are roughly on the same order of magnitude (단위 통일?)
- mask pruning (inference 단계에서 Panoptic Head 내 logit 계산에 사용할 mask 결정하는 과정)
  - instance segmentation head에서 얻은 여러가지 mask 중에서 확률이 높은 순으로 정렬
  - mask를 활용할 지 결정할 때, 이미 사용하기로 결정한 mask들과의 IoU가 특정 threshold 이상이라면 해당 마스크 제외



## 4. Experiments

* 기존 방법론들과 비교해본 결과 COCO, Cityscapes, 자체 데이터셋에서 Panoptic Segmentation 성능을 더 높히고, inference runtime을 줄일 수 있었다.
* Ablation Study
  * ![image-20220217153719472](https://user-images.githubusercontent.com/38153357/154634243-7cdfab60-4291-419a-aacd-958954bfc860.png)
  * panoptic head 유의미
  * instance class assignment 유의미
  * RoI loss 유의미



## 주관적 정리 및 참고사항

* oversimplified 3줄 요약
   1. panoptic segmentation은 semantic segmentation과 instance segmentation을 동시에 해결하는 task이며, UPSNet은 이 task를 해결하기 위해 고안되었다
   2. UPSNet은 train 단계에서 Region Proposal Network를 end-to-end 방식으로 학습시키고, 제안된 영역은 semantic / instance segmentation head에서 활용된다
   3. Recognition Quality(RQ)와 Semantic Quality(SQ)를 합친 Panoptic Quality(PQ) 지표 등 총 8개의 loss를 활용하여 학습 시킨다
* 참고자료
   * CDM(티스토리) "[[Review] UPSNet: A Unified Panoptic Segmentation Network](https://cdm98.tistory.com/40)"
   * 약초의 숲(티스토리) "[FPN 논문(Feature Pyramid Networks for Object Detection) 리뷰](https://herbwood.tistory.com/18)"
   * 약초의 숲(티스토리) "[Mask R-CNN 논문(Mask R-CNN) 리뷰](https://herbwood.tistory.com/20)"
   * towardsdatascience "[Intersection over union (IoU) calculation for evaluating an image segmentation model](https://towardsdatascience.com/intersection-over-union-iou-calculation-for-evaluating-an-image-segmentation-model-8b22e2e84686)"
